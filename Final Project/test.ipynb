{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"dpFjc4ZylMGC"},"source":["#importing libraries\n","import pandas as pd\n","import numpy as np\n","import random as rand\n","import matplotlib.pyplot as plt\n","import tensorflow as tf \n","import tensorflow.keras\n","import sklearn as sk\n","\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import models, layers, optimizers, preprocessing\n","from tensorflow.keras.preprocessing import image_dataset_from_directory, image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Activation\n","from keras.datasets import mnist\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_DXilh9lerU","executionInfo":{"status":"ok","timestamp":1616278244038,"user_tz":240,"elapsed":28652,"user":{"displayName":"Ali Khan","photoUrl":"","userId":"09789286685912502299"}},"outputId":"68217a55-b4a4-4930-a387-3bfa6b713104"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yGSIH4GJpI8_"},"source":["directory =  \"/content/drive/Shareddrives/Team 8- Neural Network/Final Project/ECBE329_Project/ECBE329_Project\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HM8mZa6ntbPQ"},"source":["# tf.keras.preprocessing.image_dataset_from_directory(directory, labels='inferred', label_mode=\"int\", color_mode='rgb', shuffle=False, seed=None, validation_split=0.3, subset=\"training\")\n","\n","# datagen = ImageDataGenerator()\n","\n","# train = datagen.flow_from_directory(directory, class_mode='categorical')\n","# val = datagen.flow_from_directory(directory, class_mode='categorical')\n","# test = datagen.flow_from_directory(directory, class_mode='categorical')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1IVmg4TLz5Rz"},"source":["# image_dataset_from_directory(directory, labels='inferred')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"enC_iaQdeP_j"},"source":["# Model 1"]},{"cell_type":"code","metadata":{"id":"aKUeT116JzWD"},"source":["#Creation of model 1\n","model = Sequential()\n","# model.add(Conv2D(32, (3, 3), input_shape=(256, 256, 3)))\n","model.add(Conv2D(32, (3, 3), input_shape=(384, 512, 3)))\n","\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","model.add(Dense(1))\n","# model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","model.compile(loss='categorical_crossentropy', optimizer= 'rmsprop', metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fi_GXTGiJnN6"},"source":["img_height = 384\n","img_width = 512\n","batch_size = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8PxFJG7G01V","outputId":"a0cdedfb-6a13-4116-81c1-78df003e0022"},"source":["train_datagen = ImageDataGenerator(rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2) # set validation split\n","\n","train_generator = train_datagen.flow_from_directory(\n","    directory,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    # class_mode='binary',\n","    class_mode = 'categorical',\n","    subset='training') # set as training data\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    directory, # same directory as training data\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    # class_mode='binary',\n","    class_mode = 'categorical',\n","    subset='validation') # set as validation data\n","\n","model.fit_generator(\n","    train_generator,\n","    steps_per_epoch = train_generator.samples // batch_size,\n","    validation_data = validation_generator, \n","    validation_steps = validation_generator.samples // batch_size,\n","    epochs = 10\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 1816 images belonging to 5 classes.\n","Found 454 images belonging to 5 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n"," 3/56 [>.............................] - ETA: 5:33 - loss: 1.1921e-07 - accuracy: 0.8000"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rxFZl26ueJcV"},"source":["# Model 2\n"]},{"cell_type":"code","metadata":{"id":"-FngH6aVcRsE"},"source":["#Creation of model 2\n","model2 = Sequential()\n","# model.add(Conv2D(32, (3, 3), input_shape=(256, 256, 3)))\n","model2.add(Conv2D(32, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(28,28,1)))\n","# model2.add(Conv2D(32, (3, 3), input_shape=(384, 512, 3)))\n","# model2.add(Activation('relu'))\n","model2.add(MaxPooling2D(pool_size=(2, 2)))\n","model2.add(Conv2D(32, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(12,12,20)))\n","model2.add(MaxPooling2D(pool_size=(2, 2)))\n","model2.add(Flatten())\n","model2.add(Dense(64))\n","model2.add(Activation('relu'))\n","model2.add(Dense(1))\n","# model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","model2.compile(loss='categorical_crossentropy', optimizer= 'rmsprop', metrics = ['accuracy'])\n","\n","# # \n","# # \n","# # \n","# #CNN2\n","# # Define model\n","# CNN2 = Sequential()\n","# # CNN2.add(Dropout(0.5, input_shape=(28,28,1)))\n","# #CNN2.add(Dense(28, input_shape=(28,28,1), activation='sigmoid'))\n","# CNN2.add(Conv2D(32, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(28,28,1)))\n","# CNN2.add(MaxPooling2D(pool_size=(2, 2)))\n","# CNN2.add(Conv2D(32, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(12,12,20)))\n","# CNN2.add(MaxPooling2D(pool_size=(2, 2)))\n","# CNN2.add(Flatten())\n","# CNN2.add(Dense(100, activation='relu'))\n","# CNN2.add(Dense(10, activation='softmax'))\n","# CNN2.summary()\n","\n","# # Compile and fit\n","# CNN2.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","# hist = CNN2.fit(X_train, y_train, batch_size=10, epochs=60, validation_data= (X_val, y_val), verbose=2, shuffle=True)\n","\n","# # Evaluate\n","# score = CNN2.evaluate(X_test, y_test, verbose=0)\n","# accuracy = 100*score[1]\n","# print('Test accuracy: %.4f%%' % accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZwzRyB9PeEm5"},"source":["train_datagen2 = ImageDataGenerator(rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2) # set validation split\n","\n","train_generator2 = train_datagen2.flow_from_directory(\n","    directory,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    # class_mode='binary',\n","    class_mode = 'categorical',\n","    subset='training') # set as training data\n","\n","validation_generator2 = train_datagen2.flow_from_directory(\n","    directory, # same directory as training data\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    # class_mode='binary',\n","    class_mode = 'categorical',\n","    subset='validation') # set as validation data\n","\n","model2.fit_generator(\n","    train_generator2,\n","    steps_per_epoch = train_generator2.samples // batch_size,\n","    validation_data = validation_generator2, \n","    validation_steps = validation_generator2.samples // batch_size,\n","    epochs = 10\n","    )"],"execution_count":null,"outputs":[]}]}